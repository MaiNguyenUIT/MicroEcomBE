# ./logstash/pipeline/logstash.conf

input {
  kafka {
    bootstrap_servers => "kafka-kraft:29092" # Địa chỉ Kafka broker
    topics => ["application-logs"]            # Topic để đọc log
    group_id => "logstash_kafka_consumer"    # Group ID cho consumer
    codec => "json"                          # Định dạng message mong đợi từ Kafka
    # auto_offset_reset => "latest"
    # consumer_threads => 3
  }
}

filter {
  # Kiểm tra điều kiện cho log_event_type
  if [log_event_type] in ["API_REQUEST", "API_RESPONSE"] {
    mutate {
      add_tag => ["api_event"] # Thêm tag "api_event"
    }
    # Bạn có thể thêm các xử lý khác dành riêng cho API_REQUEST/API_RESPONSE ở đây
    # Ví dụ:
    # if [log_event_type] == "API_RESPONSE" and [http_status_code] >= 400 {
    #   mutate { add_tag => ["api_error_response"] }
    # }
  }

  # (Tùy chọn) Xử lý timestamp nếu cần
  # Các log mẫu của bạn đã có trường "@timestamp" hợp lệ (ví dụ: "2025-05-12T22:32:34.536237064Z")
  # được tạo bởi LogstashEncoder trong ứng dụng Spring Boot.
  # Logstash sẽ tự động sử dụng trường này.
  # Nếu bạn có một trường timestamp gốc khác từ ứng dụng và muốn dùng nó, bạn có thể dùng bộ lọc date:
  # date {
  #   match => [ "ten_truong_timestamp_cua_ban", "ISO8601" ] # Thay bằng tên trường và định dạng thực tế
  #   target => "@timestamp"
  # }
}

output {
  elasticsearch {
    hosts => ["http://elasticsearch:9200"] # Địa chỉ Elasticsearch
    index => "application-logs-%{+YYYY.MM.dd}" # Mẫu đặt tên index
    # user => "elastic"
    # password => "your_password"
  }
  # Bật stdout để debug trong quá trình phát triển
  stdout { codec => rubydebug }
}